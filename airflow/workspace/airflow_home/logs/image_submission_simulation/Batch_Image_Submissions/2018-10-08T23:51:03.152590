[2018-10-08 23:51:04,933] {models.py:167} INFO - Filling up the DagBag from /home/ec2-user/Deep_Images_Hub/airflow/workspace/airflow_home/dags/images_submission_simulation.py
[2018-10-08 23:51:05,167] {base_task_runner.py:112} INFO - Running: ['bash', '-c', u'airflow run image_submission_simulation Batch_Image_Submissions 2018-10-08T23:51:03.152590 --job_id 17 --raw -sd DAGS_FOLDER/images_submission_simulation.py']
[2018-10-08 23:51:05,376] {base_task_runner.py:95} INFO - Subtask: [2018-10-08 23:51:05,376] {__init__.py:57} INFO - Using executor SequentialExecutor
[2018-10-08 23:51:05,650] {base_task_runner.py:95} INFO - Subtask: [2018-10-08 23:51:05,649] {models.py:167} INFO - Filling up the DagBag from /home/ec2-user/Deep_Images_Hub/airflow/workspace/airflow_home/dags/images_submission_simulation.py
[2018-10-08 23:51:05,837] {base_task_runner.py:95} INFO - Subtask: /usr/local/lib/python2.7/site-packages/airflow/utils/helpers.py:406: DeprecationWarning: Importing PythonOperator directly from <module 'airflow.operators' from '/usr/local/lib/python2.7/site-packages/airflow/operators/__init__.pyc'> has been deprecated. Please import from '<module 'airflow.operators' from '/usr/local/lib/python2.7/site-packages/airflow/operators/__init__.pyc'>.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
[2018-10-08 23:51:05,837] {base_task_runner.py:95} INFO - Subtask:   DeprecationWarning)
[2018-10-08 23:51:05,874] {base_task_runner.py:95} INFO - Subtask: [2018-10-08 23:51:05,874] {models.py:1126} INFO - Dependencies all met for <TaskInstance: image_submission_simulation.Batch_Image_Submissions 2018-10-08 23:51:03.152590 [queued]>
[2018-10-08 23:51:05,876] {base_task_runner.py:95} INFO - Subtask: [2018-10-08 23:51:05,876] {models.py:1126} INFO - Dependencies all met for <TaskInstance: image_submission_simulation.Batch_Image_Submissions 2018-10-08 23:51:03.152590 [queued]>
[2018-10-08 23:51:05,876] {base_task_runner.py:95} INFO - Subtask: [2018-10-08 23:51:05,876] {models.py:1318} INFO - 
[2018-10-08 23:51:05,876] {base_task_runner.py:95} INFO - Subtask: --------------------------------------------------------------------------------
[2018-10-08 23:51:05,876] {base_task_runner.py:95} INFO - Subtask: Starting attempt 1 of 1
[2018-10-08 23:51:05,877] {base_task_runner.py:95} INFO - Subtask: --------------------------------------------------------------------------------
[2018-10-08 23:51:05,877] {base_task_runner.py:95} INFO - Subtask: 
[2018-10-08 23:51:05,888] {base_task_runner.py:95} INFO - Subtask: [2018-10-08 23:51:05,888] {models.py:1342} INFO - Executing <Task(BashOperator): Batch_Image_Submissions> on 2018-10-08 23:51:03.152590
[2018-10-08 23:51:05,899] {base_task_runner.py:95} INFO - Subtask: [2018-10-08 23:51:05,899] {bash_operator.py:71} INFO - tmp dir root location: 
[2018-10-08 23:51:05,899] {base_task_runner.py:95} INFO - Subtask: /tmp
[2018-10-08 23:51:05,901] {base_task_runner.py:95} INFO - Subtask: [2018-10-08 23:51:05,900] {bash_operator.py:80} INFO - Temporary script location :/tmp/airflowtmptZCqUW//tmp/airflowtmptZCqUW/Batch_Image_SubmissionsK0uOy9
[2018-10-08 23:51:05,901] {base_task_runner.py:95} INFO - Subtask: [2018-10-08 23:51:05,901] {bash_operator.py:81} INFO - Running command: 
[2018-10-08 23:51:05,901] {base_task_runner.py:95} INFO - Subtask: 
[2018-10-08 23:51:05,901] {base_task_runner.py:95} INFO - Subtask: 
[2018-10-08 23:51:05,901] {base_task_runner.py:95} INFO - Subtask: 
[2018-10-08 23:51:05,901] {base_task_runner.py:95} INFO - Subtask: 
[2018-10-08 23:51:05,901] {base_task_runner.py:95} INFO - Subtask: 
[2018-10-08 23:51:05,901] {base_task_runner.py:95} INFO - Subtask: peg scp to-rem pySpark-cluster 1 ~/sample_labelsaa /home/ubuntu/sample_labelsaa
[2018-10-08 23:51:05,901] {base_task_runner.py:95} INFO - Subtask: 
[2018-10-08 23:51:05,901] {base_task_runner.py:95} INFO - Subtask: peg sshcmd-node pySpark-cluster 1 "touch dummy_from_airflow.txt" 
[2018-10-08 23:51:05,901] {base_task_runner.py:95} INFO - Subtask: 
[2018-10-08 23:51:05,902] {base_task_runner.py:95} INFO - Subtask: peg sshcmd-node pySpark-cluster 1 "nohup sh ~/Deep_Images_Hub/src/producer/auto_upload_for_batch.sh ~/sample_labelsaa "test"  > ~/Deep_Images_Hub/src/producer/auto_upload.log &" 
[2018-10-08 23:51:05,902] {base_task_runner.py:95} INFO - Subtask: 
[2018-10-08 23:51:05,905] {base_task_runner.py:95} INFO - Subtask: [2018-10-08 23:51:05,904] {bash_operator.py:90} INFO - Output:
[2018-10-08 23:51:08,535] {base_task_runner.py:95} INFO - Subtask: [2018-10-08 23:51:08,530] {bash_operator.py:97} INFO - Command exited with return code 0
[2018-10-08 23:51:10,175] {jobs.py:2083} INFO - Task exited with return code 0
